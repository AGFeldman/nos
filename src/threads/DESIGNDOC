			+--------------------+
			|       CS 124       |
			| PROJECT 3: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Julie Kew <julie.kew@gmail.com>
Aaron Feldman <feldmando@gmail.com>

>> Specify how many late tokens you are using on this assignment:  

>> What is the Git repository and commit hash for your submission?
   (You only need to include the commit-hash in the file you submit
   on Moodle.)

   Repository URL: https://github.com/AGFeldman/nos 
   commit TODO(agf)

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

			      THREADS
			      =======

---- LOGISTICS ----

These questions will help us to keep track of the difficulty level of
assignments, as well as keeping track of which team members worked on
which parts.

>> L1: How many hours did each team member spend on this assignment?
   Make sure that each member's total time is listed.

>> L2: What did each team member focus on for this assignment?  Keep
   descriptions to 25-30 words or less.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

The `lock` struct added the following member: 
`struct list_elem elem;`
This member allows the lock to exist in a linked list. We want each thread to
have a linked list of the locks that it holds.

The `thread` struct added the following member:
`struct list locks_held;`
This is a linked list of the locks held by the thread. This allows the thread
to receive priority donation from threads that are waiting on these locks.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Each lock has a linked list of threads that are waiting for the lock (this list
was already in the codebase as `lock.semaphore.waiters`). Additionally, each
thread has a linked list of locks that it holds.

Suppose that a high-priority thread H is waiting on a lock LM that a
medium-priority thread M holds, and M is waiting on a lock LL that a
low-priority thread L holds:

--Thread L--
    Priority=0
    ||Lock LL|| (held in Thread L's `locks_held` list)
        --Thread M-- (pointed to by Lock LL's `holder` field)
            Priority=1
            ||Lock LM|| (held in Thread M's `locks_held` list)
                --Thread H--
                    Priority=2

When we call thread_get_other_priority() to get L's priority, we see that L's
priority is 0, but it also holds Lock LL. So, we call lock_get_priority() to
get the maximum priority of all threads waiting on LL. (If L also held another
lock LL2, then we would also call lock_get_priority() for LL2). LL is only
waited on by one thread, M. We see that M's priority is 1, but it also holds
lock LM. So, we call lock_get_priority(LM). LM is only waited on by one thread,
H, who's priority is 2. So, H donates it's priority to M, and M's effective
priority becomes 2. Then, M's effective priority is 2, so it donates to L, and
L's effective priority becomes 2.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

A semaphore has a list of threads that are waiting on it. When we call
sema_up(), we iterate through the list of threads waiting on the semaphore, and
wake up a thread that has the highest priority among waiting threads.

The process of releasing a lock is basically just a call to sema_up(), so it
will also be the highest priority thread waiting on a lock is the one to wake
up.

A condition variable holds its list of waiting threads as a list of semaphores,
one thread for each semaphore. So, we iterate through the list of semaphores
and call sema_up() on the semaphore whose waiting thread is of the highest
priority.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

To enable priority donation, the only extra task that lock_acquire does() is to
push the lock onto the acquiring thread's list of locks held. The lock is
removed from this list with a call to lock_release(). 

I would say that this makes donation possible, but doesn't actually perform the
donation. The donation is performed when thread_get_other_priority(T) is called
to get the priority of thread T. When this call happens, T examines all of the
locks that it holds, and thread_get_other_priority() is again called for each
of the threads that are waiting on each of the locks that T holds. With this
setup, nested donation is handled naturally by recursion. However, it is
possible for thread_get_other_priority() to cause an infinite loop when there
is a deadlock.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When lock_release() is called, the lock is removed the `locks_held` list of the
thread that had held the lock. Then, sema_up() is called, since the lock
structure is implemented on top of a semaphore. sema_up() unblocks the
highest-priority thread that was waiting for the lock, then yields the current
thread if its priority is lower than that of the unblocked thread. This makes
it possible for the higher-priority thread to begin executing immediately once
the lock is released.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

TODO(agf)

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This was the only design that I considered seriously. State gets changed by
lock_acquire() and lock_release(), and priority is determined when
thread_get_other_priority() is called. I briefly considered storing donated
priority(s) in a field of struct `thread`, but decided against it because it
seemed bug-prone to try to keep this field up to date.


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			  SURVEY QUESTIONS
			  ================

Answering these questions is optional, but it will help us improve the
course in future years.  Feel free to tell us anything you want - these
questions are just to spur your thoughts.  Also, feel free to be completely
honest if there are issues with the assignment or the course - you won't be
penalized.  We can't fix things until we know about them.  :-)

>> In your opinion, was this assignment, or any of the parts of it, too
>> easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Were there any parts of the assignment that you felt were unnecessarily
>> tedious or pointless?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the instructor and/or TAs to more
>> effectively assist students, either for future quarters or the remaining
>> projects?

>> Any other comments?


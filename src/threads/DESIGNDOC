			+--------------------+
			|       CS 124       |
			| PROJECT 3: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Julie Kew <julie.kew@gmail.com>
Aaron Feldman <feldmando@gmail.com>

>> Specify how many late tokens you are using on this assignment: 
0

>> What is the Git repository and commit hash for your submission?
   (You only need to include the commit-hash in the file you submit
   on Moodle.)

   Repository URL: https://github.com/AGFeldman/nos 
   commit TODO(agf)

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

			      THREADS
			      =======

---- LOGISTICS ----

These questions will help us to keep track of the difficulty level of
assignments, as well as keeping track of which team members worked on
which parts.

>> L1: How many hours did each team member spend on this assignment?
   Make sure that each member's total time is listed.

   Julie: 10 hours
   Aaron: 15 or 16 hours

>> L2: What did each team member focus on for this assignment?  Keep
>> descriptions to 25-30 words or less.

   Julie: Timer sleeping, debugging
   Aaron: Priority donation, MLFQ, debugging

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/*! States in a thread's life cycle. */
enum thread_status {
    THREAD_RUNNING,     /*!< Running thread. */
    THREAD_READY,       /*!< Not running but ready to run. */
    THREAD_BLOCKED,     /*!< Waiting for an event to trigger. */
    THREAD_SLEEPING,    /*!< Waiting for a set length of time. */
    THREAD_DYING        /*!< About to be destroyed. */
};
THREAD_SLEEPING is a new thread status option used when the thread will be 
inactive for a predetermined length of time.

Additionally, the thread struct has a new member, int64_t wake_time, which is
used when the thread is in the sleep list to mark when it should be woken.

/*! List of sleeping processes. Processes in this list are kept
    sorted with least time to sleep at the front. */
static struct list sleep_list;
Analogous to ready_list, sleep_list keeps track of sleeping threads and their
wake times.

/*! Soonest wake time of all threads in sleep_list. */
static int64_t soonest_wake;
soonest_wake is a shortcut to allow the timer interrupt handler to avoid
traversing sleep_list when no threads are ready to be woken.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

timer_sleep disables interrupts if they were enabled, sets the status of the
current thread to sleeping, sets its wake time, inserts it into sleep_list in
the proper position (earliest to wake first), and then calls schedule. 
When schedule returns to the thread (presumably after running some other 
threads), timer_sleep enables interrupts and returns.

To be woken, sleeping threads rely on thread_tick, called by the timer interrupt
handler every tick. If any threads are ready to be woken (as indicated by 
soonest_wake), thread_tick iterates from the front of sleep_list, checking
on and waking threads until it finds one that should not yet be woken.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
sleep_list is kept sorted by thread_sleep so that the timer interrupt handler
need not search through the entire list. The soonest wake time is stored as a 
global variable so that it need not access the list at all if no threads are
ready to be woken. And thread_tick also calls timer_ticks only
once and stores the result (we found this made a small difference).

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

timer_sleep turns off interrupts so that the thread going to sleep (setting
wake time, being added to sleep_list, changing status) happens atomically,
which means that on a single CPU system, it is not possible for multiple 
threads to call timer_sleep simultaneously. One must finish before the next
can begin.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Interrupts are disabled so a thread cannot be interrupted while going to sleep.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered the slightly different design of having an unsorted sleep list,
which would lead to less time for a thread to go to sleep but more time for
threads to wake up. We strongly preferred this design because waking happens
in an interrupt handler, which we want to keep as short as possible.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

The `lock` struct added the following member: 
`struct list_elem elem;`
This member allows the lock to exist in a linked list. We want each thread to
have a linked list of the locks that it holds.

The `thread` struct added the following member:
`struct list locks_held;`
This is a linked list of the locks held by the thread. This allows the thread
to receive priority donation from threads that are waiting on these locks.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Each lock has a linked list of threads that are waiting for the lock (this list
was already in the codebase as `lock.semaphore.waiters`). Additionally, each
thread has a linked list of locks that it holds.

Suppose that a high-priority thread H is waiting on a lock LM that a
medium-priority thread M holds, and M is waiting on a lock LL that a
low-priority thread L holds:

--Thread L--
    Priority=0
    ||Lock LL|| (held in Thread L's `locks_held` list)
        --Thread M-- (pointed to by Lock LL's `holder` field)
            Priority=1
            ||Lock LM|| (held in Thread M's `locks_held` list)
                --Thread H--
                    Priority=2

When we call thread_get_other_priority() to get L's priority, we see that L's
priority is 0, but it also holds Lock LL. So, we call lock_get_priority() to
get the maximum priority of all threads waiting on LL. (If L also held another
lock LL2, then we would also call lock_get_priority() for LL2). LL is only
waited on by one thread, M. We see that M's priority is 1, but it also holds
lock LM. So, we call lock_get_priority(LM). LM is only waited on by one thread,
H, who's priority is 2. So, H donates it's priority to M, and M's effective
priority becomes 2. Then, M's effective priority is 2, so it donates to L, and
L's effective priority becomes 2.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

A semaphore has a list of threads that are waiting on it. When we call
sema_up(), we iterate through the list of threads waiting on the semaphore, and
wake up a thread that has the highest priority among waiting threads.

The process of releasing a lock is basically just a call to sema_up(), so it
will also be the highest priority thread waiting on a lock is the one to wake
up.

A condition variable holds its list of waiting threads as a list of semaphores,
one thread for each semaphore. So, we iterate through the list of semaphores
and call sema_up() on the semaphore whose waiting thread is of the highest
priority.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

To enable priority donation, the only extra task that lock_acquire does() is to
push the lock onto the acquiring thread's list of locks held. The lock is
removed from this list with a call to lock_release(). 

I would say that this makes donation possible, but doesn't actually perform the
donation. The donation is performed when thread_get_other_priority(T) is called
to get the priority of thread T. When this call happens, T examines all of the
locks that it holds, and thread_get_other_priority() is again called for each
of the threads that are waiting on each of the locks that T holds. With this
setup, nested donation is handled naturally by recursion. However, it is
possible for thread_get_other_priority() to cause an infinite loop when there
is a deadlock.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When lock_release() is called, the lock is removed the `locks_held` list of the
thread that had held the lock. Then, sema_up() is called, since the lock
structure is implemented on top of a semaphore. sema_up() unblocks the
highest-priority thread that was waiting for the lock, then yields the current
thread if its priority is lower than that of the unblocked thread. This makes
it possible for the higher-priority thread to begin executing immediately once
the lock is released.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A race condition might occur if two threads were to change their priorities
simultaneously without disabling interrupts. Depending on which thread gets
the CPU to iterate through ready_list, a thread earlier in the list with a 
lower priority might wake, or a thread later in the list with higher priority.
We could avoid this problem by locking ready_list, but schedule() needs to 
access ready_list, and it is called from the timer interrupt handler. Since
interrupts are not allowed to wait on locks, we could not have schedule()
waiting to access ready_list. Instead, our implementation does not use a lock

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This was the only design that I considered seriously. State gets changed by
lock_acquire() and lock_release(), and priority is determined when
thread_get_other_priority() is called. I briefly considered storing donated
priority(s) in a field of struct `thread`, but decided against it because it
seemed bug-prone to try to keep this field up to date.


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

`typedef int FPNUM`: To store fixed-point real numbers
`FIXED_POINT_F`: Macro defined to by 16384, which is 2^14
Global int/FPNUM `system_load_avg`: Store the most recently computed system
                                    load average.
`int nice`: A member of the `thread` struct, used to store the thread's nice
            value
`int recent_cpu`: A member of the `thread` struct, used to store the thread's
                  recent cpu value.


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

                 >> Niceness:
                 >> 0   1   2
timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59   A 
 4      4   0   0  62  61  59   A
 8      8   0   0  61  61  59   A
12      12  0   0  60  61  59   B
16      12  4   0  60  60  59   B
20      12  8   0  60  59  59   A
24      16  8   0  59  59  59   A
28      20  8   0  58  59  59   C
32      20  8   4  58  59  58   B
36      20  12  4  58  58  58   B

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

It is not specified whether the running thread should increment its recent_cpu
value before or after priorities are recalculated. We say that it increments
before. This is the same behavior as our scheduler.

If there are multiple non-running threads that have a higher priority than the
running thread, it is not specified which thread gets run next. We run the
least-recently-run thread; this matches the behavior of our scheduler, which
pushes threads to the back of the ready_list when they are done running, and
runs the first thread in the ready list that has the highest priority.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

All of the work to update thread priorities, recent_cpu, and load_avg is done
with calls from inside timer_interrupt(), which is the external timer interrupt
handler. This same handler also calls thread_tick(), which sometimes calls
intr_yield_on_return() to enable scheduling and preemption.

So, little scheduling work is actually done inside an interrupt context, but
updating the various values needed for scheduling does take a fair amount of
work. This might degrade performance if it forces us to remain in interrupts
for longer and prevents other interrupts from being handled on time. 

Side note: We could optimize the code that occurs in the interrupt context. For
example, instead of calculating the updated priority for all threads once per 4
timer ticks, only calculate the updated the priority of the *current* thread,
as long as load_avg has not changed and the recent_cpu values of other threads
have not been re-calculated. 


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

We use one queue to hold all ready threads, instead of segregating the threads
into 64 queues based on priority. Additionally, we do not attempt to sort our
queue based on thread priority. This approach keeps the code simple, but it
means that we need to iterate through all threads to find one with the highest
priority, so it might be possible to squeeze better performance out of other
approaches.

If we had more time, we might try to use 64 queues. However, there are also
other optimizations that we could try first, such as the "side note" in
question C4.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

I created an abstraction layer for fixed-point math. The abstraction layer's
functions are basically the same functions that are summarized in the table at
the end of section "B.6 Fixed-Point Real Arithmetic", and their implementation
uses straightforward C arithmetic (i.e., no bit shifting). I think that this
abstraction layer makes the code easier to understand and makes bugs
significantly less likely. By marking the functions as `inline`, we are likely
to avoid function call overhead. However, it is possible that use of this
abstraction layer makes it hard or impossible to apply some micro-optimizations
to long fixed-point arithmetic formulas.

			  SURVEY QUESTIONS
			  ================

Answering these questions is optional, but it will help us improve the
course in future years.  Feel free to tell us anything you want - these
questions are just to spur your thoughts.  Also, feel free to be completely
honest if there are issues with the assignment or the course - you won't be
penalized.  We can't fix things until we know about them.  :-)

>> In your opinion, was this assignment, or any of the parts of it, too
>> easy or too hard?  Did it take too long or too little time?

Assignment was reasonable

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Were there any parts of the assignment that you felt were unnecessarily
>> tedious or pointless?

It was unclear how much jitter should affect the tests. It seems that jitter
would clearly have *some* influence on e.g. recent cpu time.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

Hint: Make sure to initialize your lists.

>> Do you have any suggestions for the instructor and/or TAs to more
>> effectively assist students, either for future quarters or the remaining
>> projects?

>> Any other comments?

